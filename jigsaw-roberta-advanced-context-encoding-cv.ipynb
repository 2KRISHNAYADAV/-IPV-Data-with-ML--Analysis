{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:47.768437Z","iopub.execute_input":"2025-07-28T16:45:47.768762Z","iopub.status.idle":"2025-07-28T16:45:47.779637Z","shell.execute_reply.started":"2025-07-28T16:45:47.768737Z","shell.execute_reply":"2025-07-28T16:45:47.778700Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -q transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:47.780922Z","iopub.execute_input":"2025-07-28T16:45:47.781242Z","iopub.status.idle":"2025-07-28T16:45:52.505362Z","shell.execute_reply.started":"2025-07-28T16:45:47.781219Z","shell.execute_reply":"2025-07-28T16:45:52.504262Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:52.506682Z","iopub.execute_input":"2025-07-28T16:45:52.506963Z","iopub.status.idle":"2025-07-28T16:45:52.512988Z","shell.execute_reply.started":"2025-07-28T16:45:52.506939Z","shell.execute_reply":"2025-07-28T16:45:52.512033Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n\nprint(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:52.515880Z","iopub.execute_input":"2025-07-28T16:45:52.516224Z","iopub.status.idle":"2025-07-28T16:45:52.576122Z","shell.execute_reply.started":"2025-07-28T16:45:52.516198Z","shell.execute_reply":"2025-07-28T16:45:52.574718Z"}},"outputs":[{"name":"stdout","text":"Train shape: (2029, 9), Test shape: (10, 8)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"*Preprocess Text*","metadata":{}},{"cell_type":"markdown","source":"# Tokenizer & Model Name","metadata":{}},{"cell_type":"code","source":"def build_input_text(row):\n    return (\n        f\"Rule: {row['rule']} \"\n        f\"Positive Examples: {row['positive_example_1']} {row['positive_example_2']} \"\n        f\"Negative Examples: {row['negative_example_1']} {row['negative_example_2']} \"\n        f\"Comment: {row['body']}\"\n    )\n\ntrain['input_text'] = train.apply(build_input_text, axis=1)\ntest['input_text'] = test.apply(build_input_text, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:52.577133Z","iopub.execute_input":"2025-07-28T16:45:52.577714Z","iopub.status.idle":"2025-07-28T16:45:52.620442Z","shell.execute_reply.started":"2025-07-28T16:45:52.577691Z","shell.execute_reply":"2025-07-28T16:45:52.619539Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model_name = \"microsoft/deberta-v3-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef encode(examples):\n    return tokenizer(examples['input_text'], truncation=True, padding='max_length', max_length=256)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:52.621405Z","iopub.execute_input":"2025-07-28T16:45:52.621698Z","iopub.status.idle":"2025-07-28T16:45:57.472067Z","shell.execute_reply.started":"2025-07-28T16:45:52.621671Z","shell.execute_reply":"2025-07-28T16:45:57.471239Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f516e4cc5d4176a90d7266c4c1dd8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc051426a6647a6aedebd6532b1b9b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c745ba495bc4191a2d877b86bc3b040"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Cross-Validation Setup","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:57.473097Z","iopub.execute_input":"2025-07-28T16:45:57.473399Z","iopub.status.idle":"2025-07-28T16:45:57.478479Z","shell.execute_reply.started":"2025-07-28T16:45:57.473377Z","shell.execute_reply":"2025-07-28T16:45:57.477654Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./models\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    report_to=\"none\"  # Disable W&B\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:57.479434Z","iopub.execute_input":"2025-07-28T16:45:57.479770Z","iopub.status.idle":"2025-07-28T16:45:57.515259Z","shell.execute_reply.started":"2025-07-28T16:45:57.479743Z","shell.execute_reply":"2025-07-28T16:45:57.514341Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# . Training Loop for 5 Folds","metadata":{}},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['rule_violation'])):\n    print(f\"***** Fold {fold+1} *****\")\n    \n    train_fold = train.iloc[train_idx]\n    val_fold = train.iloc[val_idx]\n    \n    # Convert to HF Dataset\n    hf_train = Dataset.from_pandas(train_fold[['input_text', 'rule_violation']])\n    hf_val = Dataset.from_pandas(val_fold[['input_text', 'rule_violation']])\n    hf_test = Dataset.from_pandas(test[['input_text']])\n    \n    # Tokenize\n    hf_train = hf_train.map(encode, batched=True)\n    hf_val = hf_val.map(encode, batched=True)\n    hf_test = hf_test.map(encode, batched=True)\n    \n    hf_train = hf_train.rename_column('rule_violation', 'labels')\n    hf_val = hf_val.rename_column('rule_violation', 'labels')\n    \n    hf_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n    hf_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n    hf_test.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n    \n    # Load Model\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=f\"./fold_{fold+1}\",\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=2,\n        learning_rate=2e-5,\n        weight_decay=0.01,\n        logging_dir=\"./logs\",\n        logging_steps=50,\n        save_total_limit=1\n    )\n    \n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        probs = torch.softmax(torch.tensor(logits), dim=-1)[:, 1].numpy()\n        auc = roc_auc_score(labels, probs)\n        return {\"roc_auc\": auc}\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=hf_train,\n        eval_dataset=hf_val,\n        compute_metrics=compute_metrics\n    )\n    \n    trainer.train()\n    \n    # Validation Predictions\n    val_preds = trainer.predict(hf_val).predictions\n    val_probs = torch.softmax(torch.tensor(val_preds), dim=-1)[:, 1].numpy()\n    oof_preds[val_idx] = val_probs\n    \n    # Test Predictions\n    test_preds_fold = trainer.predict(hf_test).predictions\n    test_probs_fold = torch.softmax(torch.tensor(test_preds_fold), dim=-1)[:, 1].numpy()\n    test_preds += test_probs_fold / 5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T16:45:57.516296Z","iopub.execute_input":"2025-07-28T16:45:57.516662Z"}},"outputs":[{"name":"stdout","text":"***** Fold 1 *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1623 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac94299ca36741af9af4036e86429de4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/406 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b324ded8324d1ebd59edc7a8fad377"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027f530d0f424e4a9b2eba29baa25712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ed67dffe1434482841ef27c440165c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b915c060c54df2ba173a64896bd94e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 12/406 02:23 < 1:33:55, 0.07 it/s, Epoch 0.05/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# Out-of-Fold Score","metadata":{}},{"cell_type":"code","source":"print(\"OOF ROC-AUC:\", roc_auc_score(train['rule_violation'], oof_preds))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'row_id': test['row_id'],\n    'rule_violation': test_preds\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(submission.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}